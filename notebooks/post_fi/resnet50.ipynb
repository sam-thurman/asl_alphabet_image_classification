{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.datasets import cifar100\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage.transform import resize\n",
    "# from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60901 images belonging to 29 classes.\n",
      "Found 26100 images belonging to 29 classes.\n",
      "Found 30 images belonging to 29 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 29\n",
    "nb_epochs = 10\n",
    "img_sz = (100, 100)\n",
    "\n",
    "# data paths\n",
    "train_path = '../../data/asl_alphabet_train/'\n",
    "validation_path = '../../data/asl_alphabet_validation/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   validation_split=0.3)\n",
    "valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=img_sz,\n",
    "        color_mode='rgb',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=img_sz,\n",
    "        color_mode='rgb',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "validation_generator = valid_datagen.flow_from_directory(\n",
    "        validation_path,\n",
    "        target_size=img_sz,\n",
    "        color_mode='rgb',\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 100, 100, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_generator)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_in = keras.Input(shape=next(train_generator)[0].shape[1:])\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_tensor=new_in)\n",
    "\n",
    "for layer in resnet_model.layers:\n",
    "    if isinstance(layer, BatchNormalization):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(UpSampling2D())\n",
    "# model.add(UpSampling2D())\n",
    "# model.add(UpSampling2D())\n",
    "model.add(resnet_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(.25))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1904/1904 [==============================] - 4060s 2s/step - loss: 0.3441 - accuracy: 0.9025 - val_loss: 11.3335 - val_accuracy: 0.1000\n",
      "Epoch 2/5\n",
      "1904/1904 [==============================] - 4150s 2s/step - loss: 0.0636 - accuracy: 0.9802 - val_loss: 13.2761 - val_accuracy: 0.1000\n",
      "Training time: -8217.994802951813\n"
     ]
    }
   ],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                           min_delta=0,\n",
    "                                           patience=1,\n",
    "                                           verbose=0,\n",
    "                                           mode=\"auto\",\n",
    "                                           baseline=None,\n",
    "                                           restore_best_weights=False)\n",
    "\n",
    "callbacks = [early_stop]\n",
    "t=time.time()\n",
    "historytemp = model.fit(train_generator,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        epochs=5,\n",
    "                        validation_data=validation_generator,\n",
    "                        callbacks=callbacks)\n",
    "print('Training time: %s' % (t - time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python36964bitlearnenvcondae7e6328cec2744cc9785efcdf88db667"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
