{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.datasets import cifar100\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage.transform import resize\n",
    "# from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1654 images belonging to 10 classes.\n",
      "Found 409 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "nb_epochs = 10\n",
    "img_sz = (224, 224)\n",
    "\n",
    "# data paths\n",
    "data_path = '../../../data/asl_digits/'\n",
    "\n",
    "# train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "#                                    rescale=1./255,\n",
    "#                                    shear_range=0.2,\n",
    "#                                    zoom_range=0.2,\n",
    "#                                    horizontal_flip=True,\n",
    "#                                    validation_split=0.2)\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
    "# valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=img_sz,\n",
    "        color_mode='rgb',\n",
    "        batch_size=10,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=img_sz,\n",
    "        color_mode='rgb',\n",
    "        batch_size=10,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "# validation_generator = valid_datagen.flow_from_directory(\n",
    "#         validation_path,\n",
    "#         target_size=img_sz,\n",
    "#         color_mode='rgb',\n",
    "#         batch_size=32,\n",
    "#         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_generator)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet() #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x = base_model.layers[-6].output\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     layer.trainable=False\n",
    "# or if we want to set the first 20 layers of the network to be non-trainable\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(resnet_model)\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(.25))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizers.Adam(learning_rate=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "  1/166 [..............................] - ETA: 0s - loss: 3.6288 - accuracy: 0.0000e+00WARNING:tensorflow:From /Users/sam/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "166/166 [==============================] - 55s 334ms/step - loss: 0.5715 - accuracy: 0.8356 - val_loss: 0.5102 - val_accuracy: 0.8435\n",
      "Epoch 2/15\n",
      "166/166 [==============================] - 58s 352ms/step - loss: 0.0945 - accuracy: 0.9837 - val_loss: 0.3643 - val_accuracy: 0.8851\n",
      "Epoch 3/15\n",
      "166/166 [==============================] - 84s 503ms/step - loss: 0.0462 - accuracy: 0.9958 - val_loss: 0.3024 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "166/166 [==============================] - 73s 439ms/step - loss: 0.0341 - accuracy: 0.9952 - val_loss: 0.3475 - val_accuracy: 0.8802\n",
      "Epoch 5/15\n",
      "166/166 [==============================] - 65s 390ms/step - loss: 0.0194 - accuracy: 0.9988 - val_loss: 0.3376 - val_accuracy: 0.8851\n",
      "Epoch 6/15\n",
      "166/166 [==============================] - 67s 404ms/step - loss: 0.0135 - accuracy: 0.9994 - val_loss: 0.3414 - val_accuracy: 0.8851\n",
      "Epoch 7/15\n",
      "166/166 [==============================] - 70s 420ms/step - loss: 0.0112 - accuracy: 0.9994 - val_loss: 0.3104 - val_accuracy: 0.8875\n",
      "Epoch 8/15\n",
      "166/166 [==============================] - 68s 412ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.2948 - val_accuracy: 0.8924\n",
      "Epoch 9/15\n",
      "166/166 [==============================] - 68s 409ms/step - loss: 0.0086 - accuracy: 0.9994 - val_loss: 0.3229 - val_accuracy: 0.8802\n",
      "Epoch 10/15\n",
      "166/166 [==============================] - 69s 414ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.4833 - val_accuracy: 0.8460\n",
      "Epoch 11/15\n",
      "166/166 [==============================] - 68s 407ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.8631\n",
      "Epoch 12/15\n",
      "166/166 [==============================] - 69s 413ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.8680\n",
      "Epoch 13/15\n",
      "166/166 [==============================] - 68s 411ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.8729\n",
      "Epoch 14/15\n",
      "166/166 [==============================] - 68s 409ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.2997 - val_accuracy: 0.8998\n",
      "Epoch 15/15\n",
      "166/166 [==============================] - 69s 413ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.8924\n",
      "Training time: -1025.700748682022\n"
     ]
    }
   ],
   "source": [
    "EarlyStop = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                           min_delta=0,\n",
    "                                           patience=1,\n",
    "                                           verbose=0,\n",
    "                                           mode=\"auto\",\n",
    "                                           baseline=None,\n",
    "                                           restore_best_weights=False)\n",
    "TensorBoard = keras.callbacks.TensorBoard(log_dir='./tensorboard_logs')\n",
    "\n",
    "callbacks = [TensorBoard]\n",
    "t=time.time()\n",
    "historytemp = model.fit(train_generator,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        epochs=15,\n",
    "                        validation_data=test_generator,\n",
    "                        callbacks=callbacks)\n",
    "print('Training time: %s' % (t - time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(test_generator)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open('../../../data/asl_digits/5/IMG_1133.JPG').resize((224,224))\n",
    "im = np.expand_dims(np.array(im),axis=0)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(np.array(im))\n",
    "prediction.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4,  2,  1,  4,  5,  5,  6,  4,  6],\n",
       "       [10,  2,  0,  5,  4,  4,  4,  1,  6,  5],\n",
       "       [ 0,  6,  6,  4,  3,  3,  7,  4,  7,  1],\n",
       "       [ 4,  4,  2,  7,  3,  3,  9,  3,  2,  4],\n",
       "       [ 3,  4,  1,  4,  4,  6, 10,  2,  5,  2],\n",
       "       [ 7,  8,  1,  1,  1,  3,  7,  3,  6,  4],\n",
       "       [ 4,  2,  3,  5,  2,  5,  8,  5,  4,  3],\n",
       "       [ 3,  4,  4,  2,  2,  6,  8,  3,  5,  4],\n",
       "       [ 2,  3,  2,  4,  5,  3, 10,  4,  3,  5],\n",
       "       [ 4,  4,  3,  3,  0,  6,  6,  3,  5,  6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe73e506ac8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_plot_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/digits_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('learn-env': conda)",
   "language": "python",
   "name": "python36964bitlearnenvcondae7e6328cec2744cc9785efcdf88db667"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
