{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "# from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input, decode_predictions\n",
    "# from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, UpSampling2D, Flatten, BatchNormalization, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.datasets import cifar100\n",
    "import tensorflow as tf\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from skimage.transform import resize\n",
    "# from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    def eraser(input_img):\n",
    "        img_h, img_w, img_c = input_img.shape\n",
    "        p_1 = np.random.rand()\n",
    "\n",
    "        if p_1 > p:\n",
    "            return input_img\n",
    "\n",
    "        while True:\n",
    "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "            r = np.random.uniform(r_1, r_2)\n",
    "            w = int(np.sqrt(s / r))\n",
    "            h = int(np.sqrt(s * r))\n",
    "            left = np.random.randint(0, img_w)\n",
    "            top = np.random.randint(0, img_h)\n",
    "\n",
    "            if left + w <= img_w and top + h <= img_h:\n",
    "                break\n",
    "\n",
    "        if pixel_level:\n",
    "            c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "        else:\n",
    "            c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "        input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "        return input_img\n",
    "\n",
    "    return eraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1654 images belonging to 10 classes.\n",
      "Found 409 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "nb_epochs = 10\n",
    "img_sz = (224, 224)\n",
    "\n",
    "# data paths\n",
    "data_path = '../../../data/asl_digits/'\n",
    "\n",
    "# train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "#                                    rescale=1./255,\n",
    "#                                    shear_range=0.2,\n",
    "#                                    zoom_range=0.2,\n",
    "#                                    horizontal_flip=True,\n",
    "#                                    validation_split=0.2)\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, validation_split=0.2)\n",
    "# valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=img_sz,\n",
    "        color_mode='rgb',\n",
    "        batch_size=10,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "        data_path,\n",
    "        target_size=img_sz,\n",
    "        color_mode='rgb',\n",
    "        batch_size=10,\n",
    "        class_mode='categorical',\n",
    "        subset='validation')\n",
    "# validation_generator = valid_datagen.flow_from_directory(\n",
    "#         validation_path,\n",
    "#         target_size=img_sz,\n",
    "#         color_mode='rgb',\n",
    "#         batch_size=32,\n",
    "#         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(train_generator)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNet() #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x = base_model.layers[-6].output\n",
    "predictions = Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for layer in model.layers:\n",
    "#     layer.trainable=False\n",
    "# or if we want to set the first 20 layers of the network to be non-trainable\n",
    "for layer in model.layers[:-23]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(resnet_model)\n",
    "# model.add(GlobalAveragePooling2D())\n",
    "# model.add(Dense(256, activation='relu'))\n",
    "# model.add(Dropout(.25))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(optimizers.Adam(learning_rate=.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "166/166 [==============================] - 54s 323ms/step - loss: 0.4586 - accuracy: 0.8791 - val_loss: 0.7014 - val_accuracy: 0.7579\n",
      "Epoch 2/15\n",
      "166/166 [==============================] - 63s 377ms/step - loss: 0.1009 - accuracy: 0.9849 - val_loss: 0.3506 - val_accuracy: 0.9046\n",
      "Epoch 3/15\n",
      "166/166 [==============================] - 77s 462ms/step - loss: 0.0446 - accuracy: 0.9946 - val_loss: 0.3236 - val_accuracy: 0.9046\n",
      "Training time: -194.05204510688782\n"
     ]
    }
   ],
   "source": [
    "EarlyStop = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",\n",
    "                                           min_delta=0,\n",
    "                                           patience=1,\n",
    "                                           verbose=0,\n",
    "                                           mode=\"auto\",\n",
    "                                           baseline=None,\n",
    "                                           restore_best_weights=False)\n",
    "TensorBoard = keras.callbacks.TensorBoard(log_dir='./tensorboard_logs')\n",
    "\n",
    "callbacks = [EarlyStop, TensorBoard]\n",
    "t=time.time()\n",
    "historytemp = model.fit(train_generator,\n",
    "                        steps_per_epoch=len(train_generator),\n",
    "                        epochs=15,\n",
    "                        validation_data=test_generator,\n",
    "                        callbacks=callbacks)\n",
    "print('Training time: %s' % (t - time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(test_generator)[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.open('../../../data/asl_digits/0/IMG_1118.JPG').resize((224,224))\n",
    "np.expand_dims(im,axis=0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_generator.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_generator, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "409"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '1': 1,\n",
       " '2': 2,\n",
       " '3': 3,\n",
       " '4': 4,\n",
       " '5': 5,\n",
       " '6': 6,\n",
       " '7': 7,\n",
       " '8': 8,\n",
       " '9': 9}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5,  2,  7,  3,  1,  3,  9,  2,  4,  5],\n",
       "       [ 2,  7,  3,  1,  3,  7,  4,  6,  2,  6],\n",
       "       [ 4, 11,  4,  2,  4,  4,  3,  0,  4,  5],\n",
       "       [ 6,  1,  8,  5,  1,  6,  3,  5,  5,  1],\n",
       "       [ 5,  5,  4,  6,  3,  2,  6,  4,  1,  5],\n",
       "       [ 4,  3,  4,  5,  5,  5,  3,  4,  3,  5],\n",
       "       [ 4,  3,  4,  5,  2,  3,  4,  5,  4,  7],\n",
       "       [ 4,  5,  5,  4,  3,  6,  5,  1,  2,  6],\n",
       "       [ 4,  2,  7,  2,  3,  4,  5,  3,  5,  6],\n",
       "       [ 4,  7,  1,  7,  2,  4,  6,  3,  1,  5]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sam/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9d01a520f0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD4CAYAAACt8i4nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVNklEQVR4nO3de7BdZXnH8e+Pk0QSDhgwiECwyC3EakfwGBEqg0ZJQAXt4IBWRQY9LcrNdsbGasto1alT5DJDS5tyKQ4IlYgjg5aLF7xVA+GmgcOdlETugxAimSZnn6d/7BV7CDln7b3Pet+svfL7MGuyz97Z63k3J3nynHe973oUEZiZWTrbbe0BmJk1nROtmVliTrRmZok50ZqZJeZEa2aW2LTUAW7c7YQsyxrOnvFcjjAAXDW0PlusL9yxW7ZYN6x7MFusRYP7ZYnz9a/MyxIH4Nglt2aL9T7mZIs1b8NotlhHPnmVpnqOjc883HHOmT5nnynH64QrWjOzxJJXtGZmWY21tvYIXsaJ1syapZVvqqNTTrRm1igRY1t7CC/jRGtmzTLmRGtmlpYrWjOzxHwxzMwssX6saCUdCBwL7AkE8BhwbUSMJB6bmVnXooarDibdsCDpb4CrAAG3ALcWj6+UtCT98MzMujQ21vmRSVlFezLwxxGxcfyTks4B7gb+cUtvkjQMDAOcseMQR8/ct4Khmpl1oIZTB2VbcMeAPbbw/O7Fa1sUEUsjYigihpxkzSyrsVbnRyZlFe2ZwA8lPQCsLp57LbAfcGrKgZmZ9aSGFe2kiTYirpd0ALCA9sUwAWuAWyOifmsozMxqeDGsdNVBtPez/SrDWMzMps47w8zM0qrjD9u+H62ZNUuMdX6UkHSJpKckrRz33C6SbpL0QPHrzmXncaI1s2apdh3tfwCLN3tuCfDDiNgf+GHx9aScaM2sWSqsaCPip8Czmz19LHBZ8fgy4P1l5/EcrZk1S2tj+e8pjN9cVVgaEUtL3rZbRDwOEBGPS3p1WRwnWjNrli5WHRRJtSyxTlnyRJurO607005drs60AF8+6MkscS5aMiNLHIALBrOF4tR1z2SLtWiXbKGqkX7DwpOSdi+q2d2Bp8re4DlaM2uW9DeVuRY4sXh8IvDdsjd46sDMmqXCDQuSrgSOAOZIWgOcRftmWt+SdDLwKPDBsvM40ZpZo0QXF8NKzxXxoQleWtjNeZxozaxZ+u2mMmZmfcf3OjAzS8wVrZlZYq5ozcwSc0VrZpbYaP1u/N3zhgVJJ1U5EDOzSlR4U5mqTGVn2BcnekHSsKQVklasWbd6ot9mZla9fms3LunXE70ETLjhf/yNGo7ca3H0PDozs2714RztbsAi4HebPS/gv5OMyMxsKvpw1cF1wGBE3Ln5C5JuTjIiM7Op6LeKNiJOnuS1D1c/HDOzKarhqgMv7zKzZon6XRZyojWzZunDOVozs/7iRGtmlli/XQwzM+s7rdbWHsHLJE+072NO6hAAXLEC/vKOL2WJNf+gv88SB+DBmaWdjCszv5WvkeEVK/bKEmdkYEOWOACfeeg32WKdu9s7ssVa9Wy+q/gHVHESTx2kkyvJmlnNOdGamSXmOVozs7RizOtozczS8tSBmVli2+KqAzOzrFzRmpkl5kRrZpaYbypjZpZYDSva0p5hkg6UtFDS4GbPL043LDOzHo1F50cmkyZaSacD3wVOA1ZKOnbcy19NOTAzs560Wp0fmZRNHXwSeHNErJO0N7BM0t4RcT7tvmFbJGkYGAY4fvYCDhvcv6LhmplNLvpw6mAgItYBRMQq4AjgKEnnMEmijYilETEUEUNOsmaWVb9NHQBPSHrTpi+KpPteYA7wxpQDMzPrSYx1fpSQ9BlJd0taKelKSdv3MqSyRPsx4ImXfIaI0Yj4GHB4LwHNzJKqqKKVtCdwOjAUEW8ABoATehlSWRfcNZO89oteApqZJTVa6UWuacBMSRuBWcBjvZykdHmXmVlf6WLqQNKwpBXjjuE/nCbit8DZwKPA48DzEXFjL0PyhgUza5YuLnJFxFJg6ZZek7QzcCzwOuA54GpJH4mIy7sdkitaM2uUGBvr+CjxLuCRiHg6IjYC1wCH9jImV7Rm1izVLdt6FDhE0ixgPbAQWNHLiZxozaxZKkq0EbFc0jLgdmAUuIMJphnKJE+0iwafSR0CgAMPPC5LHIBff6qSXp0dmfdvs7PFOqV1T7ZY/7Vrnu6+I+t3yhIH4Ps7vz1bLDbk60x7Suv+bLEequIkFW6tjYizgLOmeh5XtGbWKO4ZZmaWmhOtmVliNbypjBOtmTWLK1ozs8ScaM3M0oqWpw7MzNJyRWtmlpaXd5mZpdaPiVbSAiAi4lZJrwcWA/dGxPeTj87MrFv1m6KdPNFKOgs4Cpgm6SbgrcDNwBJJB0XEVyZ43x+aM37pNa/n+Nl7VTpoM7OJxGj9Mm1ZRXsc8CbgFbRb2syNiLWS/glYDmwx0Y6/x+P98xfXr443s+aqX54tTbSjEdECXpT0UESsBYiI9ZJq+HHMbFvXjxfDNkiaFREvAm/e9KSkV1LLfzfMbJtXw8xUlmgPj4j/BYh4SW/e6cCJyUZlZtajvqtoNyXZLTz/DJDnRrNmZt3ow4rWzKyvRL57onfMidbMGiVc0ZqZJeZEa2aWlitaM7PEtslEu+rZPF1cLxzI1y32kkvz/fu0aJd8izsWrd8vW6xT163NEueCwTxxAG5ozckW67z1+ToWXziQr+tzFaKlrT2El3FFa2aNsk1WtGZmOcWYK1ozs6Rc0ZqZJRbhitbMLClXtGZmiY151YGZWVq+GGZmllgdE+123b5B0jdSDMTMrAoRnR9lJM2WtEzSvZJGJL2tlzGVNWe8dvOngHdImt3+QHFML0HNzFKpuKI9H7g+Io6TNAOY1ctJyqYO5gL3ABcBQTvRDgFfn+xN47vgnrHjEEfP3LeXsZmZda2q5V2SdgIOBz7ePm9sADb0cq6yqYMh4Dbg88DzEXEzsD4ifhIRP5noTRGxNCKGImLISdbMcmq11PEhaVjSinHH8LhT7QM8DVwq6Q5JF0naoZcxlbWyGQPOlXR18euTZe8xM9uauqloI2IpsHSCl6cBBwOnRcRySecDS4C/63ZMHSXNiFgDfFDSe4B8t0MyM+tShXO0a4A1EbG8+HoZ7UTbta6q04j4HvC9XgKZmeXQyWqCzs4TT0haLWleRNwHLKR9zaprngYws0apeNXBacAVxYqDh4GTejmJE62ZNUprrOvtAROKiDtpLwqYEidaM2uUqqYOquREa2aNMubbJJqZpeX70ZqZJbZNTh3cNyNPLh8Z6GlnXE/mt7KFytZFGOD92SIB5Plc563Pdxfo+dkiwaLBfB2LWZ8vVBU8dWBmlliVqw6q4kRrZo1Sw5kDJ1ozaxZPHZiZJeZVB2ZmidWwCa4TrZk1S+CK1swsqVFPHZiZpdX3Fa2kPwUWACsj4sY0QzIz610d52gnXdkr6ZZxjz8JXADsCJwlqac7jZuZpRSo4yOXsi0U08c9HgbeHRFfBI4E/nyiN41vePaLdQ9UMEwzs86MdXHkUpZot5O0s6RXAYqIpwEi4vfA6ERvGt8F97DB/SscrpnZ5Fqo4yOXsjnaV9JuNy4gJL2m6KMzWDxnZlYr1XayqUZZu/G9J3hpDPhA5aMxM5uisRrWgD0t74qIF4FHKh6LmdmU+aYyZmaJ1XF5lxOtmTXKmBoydWBmVlcZG6B0zInWzBql71YdmJn1m8asOqij+a0ZWRs0NtHZM57LFmu/gZ2yxJnfmpElDsC8DRPu4anejHyfa+jQ1dliVcGrDhJykjUz8NSBmVlyXt5lZpZYyxWtmVlarmjNzBKrY6Itu02imVlfCXV+dELSgKQ7JF3X65hc0ZpZoySoaM8ARoCe1yS6ojWzRml1cZSRNBd4D3DRVMbkRGtmjTKmzo/xbbeKY3iz050HfJYpFsqTTh1IeiswEhFrJc0ElgAHA/cAX42I56cS3Mysat1kxIhYCizd0muS3gs8FRG3STpiKmMqq2gvAV4sHp9Pu7XN14rnLp1KYDOzFCpszngYcIykVcBVwDslXd7LmEqbM0bEpg3cQxFxZkT8vOiEu89Eb3IXXDPbWqKLY9LzRHwuIuYWLb1OAH4UER/pZUxliXalpJOKx3dJGgKQdACwcZIBuguumW0V3czR5lK2vOsTwPmSvgA8A/xS0mpgdfGamVmtpLjxd0TcDNzc6/vLuuA+D3xc0o60pwqmAWsi4sleA5qZpTRWwxsldrRhISJeAO5KPBYzsymr4xZc7wwzs0apXz3rRGtmDeOK1swssVHVr6Z1ojWzRqlfmnWiNbOG8dRBQu9fn/P+OPm6nd43I9+3KFdnWoAzZ67NEmfVs7OzxAE4pXV/tlj78upssRbdOzNbrF0qOEffLu8yM+sX9UuzTrRm1jCeOjAzS6xVw5rWidbMGsUVrZlZYuGK1swsLVe0ZmaJeXmXmVli9UuzTrRm1jCjNUy1k26nknS6pL1yDcbMbKqii/9yKdu3+g/Ackk/k/QpSbt2clI3ZzSzraXCLriVKUu0DwNzaSfcNwP3SLpe0olFe5stcnNGM9ta+rGijYgYi4gbI+JkYA/gX4DFtJOwmVmt1LGiLbsY9pKGvBGxEbgWuFZSvlv6mJl1qBX1uxhWlmiPn+iFiFhf8VjMzKas79bRRkS+G2yamVXAW3DNzBLzFlwzs8T6burAzKzfeOrAzCyxflx1YGbWVzx1kNDZM57LFuuqoXwr285ekW+58n7k64J7w7o5WeLMy9ixeNHgftli5e36nO/vVhXqeDEs53fLzCy5qrbgStpL0o8ljUi6W9IZvY6pMRWtmRlUOnUwCvx1RNxe3NvlNkk3RcQ93Z7IidbMGiUquhgWEY8DjxePX5A0AuwJONGa2batm3bjkoaB4XFPLY2IpVv4fXsDBwHLexmTE62ZNUo3UwdFUn1ZYh1P0iDwbeDMiFjby5icaM2sUaqaOgCQNJ12kr0iIq7p9TxOtGbWKFVdDJMk4GJgJCLOmcq5vLzLzBqlwg4LhwEfBd4p6c7iOLqXMU1a0UqaAZwAPBYRP5D0YeBQYIT2pPHGXoKamaVS1RbciPg5mzU/6FXZ1MGlxe+ZJelEYBC4BlgILABOrGIQZmZV6cctuG+MiD+RNA34LbBHRLQkXQ7cNdGbxi+ZOH72Atyg0cxyqWOiLZuj3a6YPtgRmAW8snj+FcD0id7kLrhmtrVERMdHLmUV7cXAvcAA8HngakkPA4cAVyUem5lZ1+pY0Zb1DDtX0n8Wjx+T9A3gXcC/R8QtOQZoZtaNvrzxd0Q8Nu7xc8CypCMyM5uCVtTvRonesGBmjZJz7rVTTrRm1ih9N0drZtZv+nKO1sysn4x56sDMLC1XtGZmiXnVQUI5O9O+5WcvZIt169uzheKEFflizSdPF9y9d8nYwXV9vi7Cp7TuzxbrwmcPyBarikieOjAzS8xTB2ZmibmiNTNLzBWtmVlirWht7SG8jBOtmTWKt+CamSXmLbhmZom5ojUzS6wvVx1I2hf4ALAXMAo8AFwZEc8nHpuZWdfquOpg0p5hkk4H/hXYHngLMJN2wv2lpCOSj87MrEutGOv4yKWsOeMngcUR8WXaLWxeHxGfBxYD5070JknDklZIWvGLdQ9UN1ozsxJ1bM5Ylmjh/6cXXkG7Gy4R8SjugmtmNTQW0fGRS9kc7UXArZJ+BRwOfA1A0q7As4nHZmbWtb5bdRAR50v6ATAfOCci7i2ef5p24jUzq5W+XEcbEXcDd2cYi5nZlPVdRWtm1m98428zs8T6csOCmVk/qePUQSfLu8zM+kZ08V8ZSYsl3SfpQUlLeh2TK1oza5SqKlpJA8A/A+8G1tBe6nptRNzT7bmcaM2sUSqco10APBgRDwNIugo4Fug60Xa1XS3nAQw3KY5j9VesJn6mJseayhiBFeOO4XGvHQdcNO7rjwIX9BKnznO0ww2L41j9FauJn6nJsXoS424XUBxLx72sLb2llzh1TrRmZlvTGtp3K9xkLvBYLydyojUz27Jbgf0lvU7SDOAE4NpeTlTni2FLy39LX8VxrP6K1cTP1ORYlYuIUUmnAjcAA8Al0b4lQddUTPKamVkinjowM0vMidbMLLHaJdqqtrx1EOcSSU9JWpkqxrhYe0n6saQRSXdLOiNhrO0l3SLpriLWF1PFKuINSLpD0nWJ46yS9BtJd0pakTjWbEnLJN1bfM/elijOvOLzbDrWSjozUazPFH8eVkq6UtL2KeIUsc4o4tyd6vP0na29YHizxcMDwEPAPsAM4C7afcpSxDocOBhYmeFz7Q4cXDzeEbg/4ecSMFg8ng4sBw5J+Nn+CvgmcF3i/4ergDmpv1dFrMuATxSPZwCzM8QcAJ4A/ijBufcEHgFmFl9/C/h4os/xBmAlMIv2xfYfAPvn+L7V+ahbRfuHLW8RsQHYtOWtchHxUzK144mIxyPi9uLxC8AI7T/8KWJFRKwrvpxeHEmueEqaC7yHdsujRpC0E+1/hC8GiIgNEfFchtALgYci4n8SnX8aMFPSNNpJsKf1oB2YD/wqIl6MiFHgJ8AHEsXqG3VLtHsCq8d9vYZECWlrkbQ3cBDtSjNVjAFJdwJPATdFRKpY5wGfBXLcaTmAGyXdJinljqN9gKeBS4spkYsk7ZAw3iYnAFemOHFE/BY4G3gUeBx4PiJuTBGLdjV7uKRXSZoFHM1LF/1vk+qWaCvb8lZHkgaBbwNnRsTaVHEiohURb6K9k2WBpDdUHUPSe4GnIuK2qs89gcMi4mDgKODTklL1rJtGe0rpwog4CPg9kOxaAUCxGP4Y4OpE59+Z9k+GrwP2AHaQ9JEUsSJihHYT15uA62lP/42miNVP6pZoK9vyVjeSptNOsldExDU5YhY/8t4MLE5w+sOAYyStoj3F805JlyeIA0BEPFb8+hTwHdrTTCmsAdaM+ylgGe3Em9JRwO0R8WSi878LeCQino6IjcA1wKGJYhERF0fEwRFxOO3puQdSxeoXdUu0lW15qxNJoj3nNxIR5ySOtauk2cXjmbT/kt1bdZyI+FxEzI2IvWl/n34UEUmqJEk7SNpx02PgSNo/olYuIp4AVkuaVzy1kF5ui9edD5Fo2qDwKHCIpFnFn8WFtK8TJCHp1cWvrwX+jLSfrS/UagtuVLjlrYykK4EjgDmS1gBnRcTFKWLRrv4+CvymmDsF+NuI+H6CWLsDlxU3Ld4O+FZEJF16lcFuwHfaOYJpwDcj4vqE8U4Drij+sX8YOClVoGIe893AX6SKERHLJS0Dbqf9Y/wdpN0e+21JrwI2Ap+OiN8ljNUXvAXXzCyxuk0dmJk1jhOtmVliTrRmZok50ZqZJeZEa2aWmBOtmVliTrRmZon9H+5k3VpZYSjjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "cm_plot_labels = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../models/digits_model_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
