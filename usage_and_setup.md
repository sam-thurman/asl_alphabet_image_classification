#### *Google Colab* 
*The notebooks used to construct and train the models for this project, along with all notebooks exploring data preparation, were edited exlusively in Google Colaboratory.  Data used to train models was saved in Google Drive, and the work flow relied heavily on Drive's file management interface for ease of access.  As of now, there are some very sticky hardware specific errors with model weights transfering between different sessions, and as such there are issues with the exported models running on local environments.  Currently, for optimal performance of notebooks and models, it is _highly recommended_ to run them in the Google Colaboratory environment.*

## Using This Repository
In order to use this repository and replicate/play with its code, use the following steps as a guideline to download the data and set up your repository structure in Google Colab.
### Getting the Data
Download the Kaggle Dataset [here](https://www.kaggle.com/grassknoted/asl-alphabet/download "ASL data zip download") and unzip it using your prefered software.  The resulting folder will be titled `asl-alphabet` and will contain 2 sub-folders: `asl_alphabet_train` containing 29 folders of 3,000 images each, and `asl_alphabet_test` which contains 29 folders with 1 image each.  The latter is reserved as a holdout set for evaluating trained models.  If you are using this data for your own project, that's it, you're done! Simply move the data to somewhere that makes sense inside your own repository architecture.  If you are downloading the data for use in this repository, however, continue reading for an overview of replicating this project's workflow in Google Colab.
### Repo Set Up
If your typical workflow involves JupyterLab or some other notebook editor and GitHub + Google Drive integration is new to you, here's a [quick tutorial](https://medium.com/@sam.bbmgmt/integrating-google-drive-colab-with-github-bffaca97eb5b "Integrating Google Drive/Colab with GitHub") on integrating notebooks with Google Colab (Google's `.ipnyb` editor).<br>

Clone this repository into Google Drive following the steps in the tutorial and create two new folders inside of it titled `data` and `models`.  Upload `asl_alphabet_train` and `asl_alphabet_test` to Drive inside of the `data` folder.  Python scripts in this repo are set up to serve image data from this `data` folder.  The `models` folder will be used in the next section.
### Adding / Creating Models
As you'll notice, the final model isn't included in this repo, the main reason for this being GithHub's 100MB file size constraint.  After cloning down the repository and gathering the data, the last part of repo set up is adding or creating some models.  If you're using an outside model or models, make sure to move them to the `models` folder as scripts are set up to serve model files from there. If you want to replicate the final architecture used in the project, simply follow the `model_create.ipynb` notebook inside `notebooks/final/`.  Try messing with some different model architectures in the `model_create.py` file, just be sure to keep in mind your model's expected input size, as well as input and output sizes of the various helper functions.

